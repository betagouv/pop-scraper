# POP Scraper

Aspirateur de donn√©es de la [Plateforme Ouverte du Patrimoine](https://www.pop.culture.gouv.fr).

D√©velopp√© dans le cadre de [Collectif Objets](https://collectif-objets.beta.gouv.fr/)

Cod√© en Python 3 üêç avec la librairie [Scrapy](https://docs.scrapy.org/)

## Production

D√©ploy√© et disponible sur [zyte.com](https://app.zyte.com/)

## D√©veloppement local

- `poetry install`
- `poetry run scrapy crawl pop_api`

## Options

### `base_pop`

Base POP √† scrapper. Seules `memoire`, `palissy` et `merimee` sont support√©es. D√©fault `palissy`

`poetry run scrapy crawl pop_api -a base_pop=memoire`

### `max_items`

Limite le nombre d'objets √† parcourir

`poetry run scrapy crawl pop_api -a max_items=200`

### `ref`

Scrappe un seul objet grace √† sa r√©f√©rence Palissy

`poetry run scrapy crawl pop_api -a ref=PM72000741`

## Scripts

- `make split_csv_by_dpt csv_path=exports/palissy.csv`


## Rajouter une base POP (Joconde, MNR etc)

- r√©cup√©rer un item en JSON depuis le navigateur sur la page de recherche
- r√©cup√©rer le CSV de description des champs de la base dans la codebase de POP
- rajouter la classe d'Item dans items.py √† partir de ces deux fichiers compar√©s - la source de v√©rit√© est ce qu'on peut r√©cup√©rer depuis l'API de recherche
